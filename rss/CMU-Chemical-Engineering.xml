<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>CMU Chemical Engineering</title>
    <link>https://raw.githubusercontent.com/jkitchin/literature-alerts/main/rss/rss/CMU-Chemical-Engineering.xml</link>
    <description>Papers by people in the Department of Chemical Engineering at CMU</description>
    <language>en-US</language>
    <lastBuildDate>Fri, 02 May 2025 01:39:02 GMT</lastBuildDate>
    <generator>rfeed v1.1.1</generator>
    <docs>https://github.com/svpino/rfeed/blob/master/README.md</docs>
    <item>
      <title>Generative machine learning approaches to optimization</title>
      <link>https://doi.org/10.26434/chemrxiv-2025-hk886</link>
      <description>Victor Alves, John R. Kitchin, No host. None(None)] 2025. https://openalex.org/W4409750178

                Solving optimization problems, especially for nonlinear and constrained systems, is a challenge. Decades of specialized algorithms have been developed for general and special cases of root &#64257;nding, minimization (including constraints), for parameter estimation, and mapping connected spaces. These approaches typically require a model, or set of equations, and then analytical, or iterative numerical approaches can be used to &#64257;nd a solution, and in some special cases a globally best solution can be found and proven. In this work we present an alternative approach to solving these problems that is based in generative machine learning models. The idea is these models either estimate a joint probability distribution of input and output variables, or are able to transform a distribution of inputs to a distribution of outputs (or vice versa). Then, by suitable conditioning (specifying desired properties of some variables), the solutions to these problems can be obtained by sampling the distribution, or by transformation of a distribution sample to the solution space. We illustrate the approach with Gaussian mixture models, which approximate the joint probability distribution. We show examples in root &#64257;nding, unconstrained and constrained optimization, parameter estimation and mapping input and output spaces. This work is intended to be pedagogical to show how a generative model can be used to solve problems in optimization. We discuss some limitations of this approach, but conclude the approach has promise and is di&#64256;erent than existing approaches.</description>
      <author>Victor Alves, John R. Kitchin</author>
      <pubDate>Thu, 24 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.26434/chemrxiv-2025-hk886</guid>
    </item>
    <item>
      <title>Science acceleration and accessibility with self-driving labs</title>
      <link>https://doi.org/10.1038/s41467-025-59231-1</link>
      <description>Richard B. Canty, Jeffrey A. Bennett, Keith A. Brown, Tonio Buonassisi, Sergei V. Kalinin, John R. Kitchin, Benji Maruyama, R. G. Moore, Joshua Schrier, Martin Seifrid, Shijing Sun, Tejs Vegge, Milad Abolhasani, Nature Communications. 16(1)] 2025. https://openalex.org/W4409768533

                No abstract</description>
      <author>Richard B. Canty, Jeffrey A. Bennett, Keith A. Brown, Tonio Buonassisi, Sergei V. Kalinin, John R. Kitchin, Benji Maruyama, R. G. Moore, Joshua Schrier, Martin Seifrid, Shijing Sun, Tejs Vegge, Milad Abolhasani</author>
      <pubDate>Thu, 24 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.1038/s41467-025-59231-1</guid>
    </item>
    <item>
      <title>Constraining aerosol&#8211;cloud adjustments by uniting surface observations with a perturbed parameter ensemble</title>
      <link>https://doi.org/10.5194/acp-25-4547-2025</link>
      <description>August Mikkelsen, Daniel T. McCoy, Trude Eidhammer, Andrew Gettelman, Ci Song, Hamish Gordon, Isabel L. McCoy, Atmospheric chemistry and physics. 25(8)] 2025. https://openalex.org/W4409780216

                Abstract. Aerosol&#8211;cloud interactions (ACIs) are the largest source of uncertainty in inferring the magnitude of future warming consistent with the observational record. The effective radiative forcing due to ACI (ERFaci) is dominated by liquid clouds and is composed of two terms: the change in cloud albedo due to redistributing liquid over a larger number of cloud droplets (Nd) and the change in cloud macrophysical properties due to changes in cloud microphysics. These terms are, respectively, referred to as the radiative forcing due to ACI (RFaci) and aerosol&#8211;cloud adjustments. While the magnitude of RFaci is uncertain, its sign is confidently negative and results in a cooling in the historical record. In contrast, the adjustment of cloud liquid water path (LWP) to enhanced Nd and associated radiative forcing is uncertain in sign. Increased LWP in response to increased Nd is consistent with precipitation suppression, while decreased LWP in response to increased Nd is consistent with enhanced evaporation from cloud top. Observational constraints of these processes are poor in part because of causal ambiguity in the relationship between Nd and LWP. To better understand this relationship, precipitation (P), Nd, and LWP surface observations from the Eastern North Atlantic (ENA) atmospheric observatory are combined with the output from a perturbed parameter ensemble (PPE) hosted in the Community Atmosphere Model version 6 (CAM6). This allows for causal interpretation of observed covariability. Observations of precipitation and cloud from ENA constrain the range of possible LWP aerosol&#8211;cloud adjustments relative to the prior from the PPE by 15 %, resulting in a global value that is confidently positive (a historical cooling) ranging from 2.1 to 6.9 g m&#8722;2. It is found that observed covariability between Nd and LWP is dominated by coalescence scavenging and that this observed covariability is not strongly related to aerosol&#8211;cloud adjustments.</description>
      <author>August Mikkelsen, Daniel T. McCoy, Trude Eidhammer, Andrew Gettelman, Ci Song, Hamish Gordon, Isabel L. McCoy</author>
      <pubDate>Fri, 25 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.5194/acp-25-4547-2025</guid>
    </item>
    <item>
      <title>Generative machine learning approaches to optimization</title>
      <link>https://doi.org/10.26434/chemrxiv-2025-hk886-v2</link>
      <description>Victor Alves, John R. Kitchin, No host. None(None)] 2025. https://openalex.org/W4409823420

                Solving optimization problems, especially for nonlinear and constrained systems, is a challenge. Decades of specialized algorithms have been developed for general and special cases of root &#64257;nding, minimization (including constraints), for parameter estimation, and mapping connected spaces. These approaches typically require a model, or set of equations, and then analytical, or iterative numerical approaches can be used to &#64257;nd a solution, and in some special cases a globally best solution can be found and proven. In this work we present an alternative approach to solving these problems that is based in generative machine learning models. The idea is these models either estimate a joint probability distribution of input and output variables, or are able to transform a distribution of inputs to a distribution of outputs (or vice versa). Then, by suitable conditioning (specifying desired properties of some variables), the solutions to these problems can be obtained by sampling the distribution, or by transformation of a distribution sample to the solution space. We illustrate the approach with Gaussian mixture models, which approximate the joint probability distribution. We show examples in root &#64257;nding, unconstrained and constrained optimization, parameter estimation and mapping input and output spaces. This work is intended to be pedagogical to show how a generative model can be used to solve problems in optimization. We discuss some limitations of this approach, but conclude the approach has promise and is di&#64256;erent than existing approaches.</description>
      <author>Victor Alves, John R. Kitchin</author>
      <pubDate>Fri, 25 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.26434/chemrxiv-2025-hk886-v2</guid>
    </item>
    <item>
      <title>Hydrophobic Ion Pairing for Simple, Non-Toxic Transfection</title>
      <link>https://doi.org/10.1101/2025.04.25.650611</link>
      <description>Mikaela A. Gray, Michelle Seeler, Catalina Montoya, Jaeyoung Park, D. Linh, Kathryn A. Whitehead, Julie A. Champion, No host. None(None)] 2025. https://openalex.org/W4409903359

                Although biomacromolecules require intracellular delivery for therapeutic effect, existing transfection agents are often characterized by high cost, low efficiency, and/or cytotoxicity. Here, we describe a new transfection approach based on hydrophobic ion pairing (HIP), which involves the simple mixing of a hydrophobic counterion with charged biomacromolecules. Among tested cargoes (proteins, siRNA, and pDNA), the HIP siRNA system performed especially well, achieving silencing in fibroblasts (80%), T cells (90%), and neurons (70%). HIP siRNA was also highly potent in mice, with tropism dependent on the route of administration. Most notably, intraperitoneal administration enabled ~40% LAMP-1 knockdown in the pancreas, and intravenous delivery resulted in a remarkable 80% silencing in the heart. Heart delivery was also highly selectively, with no significant knockdown in the liver. Together, these data demonstrate a new, inexpensive approach to biomacromolecular delivery with the potential to target difficult-to-transfect organs, thus expanding the therapeutic potential of nucleic acids.</description>
      <author>Mikaela A. Gray, Michelle Seeler, Catalina Montoya, Jaeyoung Park, D. Linh, Kathryn A. Whitehead, Julie A. Champion</author>
      <pubDate>Mon, 28 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.1101/2025.04.25.650611</guid>
    </item>
    <item>
      <title>Event constrained programming</title>
      <link>https://doi.org/10.1016/j.compchemeng.2025.109145</link>
      <description>Daniel Ovalle, Stefan Mazzadi, Carl D. Laird, Ignacio E. Grossmann, Joshua L. Pulsipher, Computers &amp; Chemical Engineering. None(None)] 2025. https://openalex.org/W4409907298

                No abstract</description>
      <author>Daniel Ovalle, Stefan Mazzadi, Carl D. Laird, Ignacio E. Grossmann, Joshua L. Pulsipher</author>
      <pubDate>Tue, 01 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.1016/j.compchemeng.2025.109145</guid>
    </item>
    <item>
      <title>The evolving role of programming and LLMs in the development of self-driving laboratories</title>
      <link>https://doi.org/10.1063/5.0266757</link>
      <description>John R. Kitchin, APL Machine Learning. 3(2)] 2025. https://openalex.org/W4409962774

                Machine learning and automation are transforming scientific research, yet the implementation of self-driving laboratories (SDLs) remains costly and complex, and it remains difficult to learn how to use these facilities. To address this, we introduce Claude-Light, a lightweight, remotely accessible instrument designed for prototyping automation algorithms and machine learning workflows. Claude-Light integrates a REST API, a Raspberry Pi-based control system, and an RGB LED with a photometer that measures ten spectral outputs, providing a controlled but realistic experimental environment. This device enables users to explore automation at multiple levels, from basic programming and experimental design to machine learning-driven optimization. We demonstrate the application of Claude-Light in structured automation approaches, including traditional scripting, statistical design of experiments, and active learning methods. In addition, we explore the role of large language models (LLMs) in laboratory automation, highlighting their use in instrument selection, structured data extraction, function calling, and code generation. While LLMs present new opportunities for streamlining automation, they also introduce challenges related to reproducibility, security, and reliability. We discuss strategies to mitigate these risks while leveraging LLMs for enhanced efficiency in self-driving laboratories. Claude-Light provides a practical and accessible platform for students and researchers to develop automation skills and test algorithms before deploying them in larger-scale SDLs. By lowering the barrier to entry for automation in scientific research, this tool facilitates broader adoption of AI-driven experimentation and fosters innovation in autonomous laboratories.</description>
      <author>John R. Kitchin</author>
      <pubDate>Wed, 30 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.1063/5.0266757</guid>
    </item>
  </channel>
</rss>
