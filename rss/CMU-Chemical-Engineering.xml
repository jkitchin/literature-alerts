<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>CMU Chemical Engineering</title>
    <link>https://raw.githubusercontent.com/jkitchin/literature-alerts/main/rss/rss/CMU-Chemical-Engineering.xml</link>
    <description>Papers by people in the Department of Chemical Engineering at CMU</description>
    <language>en-US</language>
    <lastBuildDate>Sat, 03 May 2025 01:36:33 GMT</lastBuildDate>
    <generator>rfeed v1.1.1</generator>
    <docs>https://github.com/svpino/rfeed/blob/master/README.md</docs>
    <item>
      <title>Generative machine learning approaches to optimization</title>
      <link>https://doi.org/10.26434/chemrxiv-2025-hk886-v2</link>
      <description>Victor Alves, John R. Kitchin, No host. None(None)] 2025. https://openalex.org/W4409823420

                Solving optimization problems, especially for nonlinear and constrained systems, is a challenge. Decades of specialized algorithms have been developed for general and special cases of root &#64257;nding, minimization (including constraints), for parameter estimation, and mapping connected spaces. These approaches typically require a model, or set of equations, and then analytical, or iterative numerical approaches can be used to &#64257;nd a solution, and in some special cases a globally best solution can be found and proven. In this work we present an alternative approach to solving these problems that is based in generative machine learning models. The idea is these models either estimate a joint probability distribution of input and output variables, or are able to transform a distribution of inputs to a distribution of outputs (or vice versa). Then, by suitable conditioning (specifying desired properties of some variables), the solutions to these problems can be obtained by sampling the distribution, or by transformation of a distribution sample to the solution space. We illustrate the approach with Gaussian mixture models, which approximate the joint probability distribution. We show examples in root &#64257;nding, unconstrained and constrained optimization, parameter estimation and mapping input and output spaces. This work is intended to be pedagogical to show how a generative model can be used to solve problems in optimization. We discuss some limitations of this approach, but conclude the approach has promise and is di&#64256;erent than existing approaches.</description>
      <author>Victor Alves, John R. Kitchin</author>
      <pubDate>Fri, 25 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.26434/chemrxiv-2025-hk886-v2</guid>
    </item>
    <item>
      <title>Hydrophobic Ion Pairing for Simple, Non-Toxic Transfection</title>
      <link>https://doi.org/10.1101/2025.04.25.650611</link>
      <description>Mikaela A. Gray, Michelle Seeler, Catalina Montoya, Jaeyoung Park, D. Linh, Kathryn A. Whitehead, Julie A. Champion, No host. None(None)] 2025. https://openalex.org/W4409903359

                Although biomacromolecules require intracellular delivery for therapeutic effect, existing transfection agents are often characterized by high cost, low efficiency, and/or cytotoxicity. Here, we describe a new transfection approach based on hydrophobic ion pairing (HIP), which involves the simple mixing of a hydrophobic counterion with charged biomacromolecules. Among tested cargoes (proteins, siRNA, and pDNA), the HIP siRNA system performed especially well, achieving silencing in fibroblasts (80%), T cells (90%), and neurons (70%). HIP siRNA was also highly potent in mice, with tropism dependent on the route of administration. Most notably, intraperitoneal administration enabled ~40% LAMP-1 knockdown in the pancreas, and intravenous delivery resulted in a remarkable 80% silencing in the heart. Heart delivery was also highly selectively, with no significant knockdown in the liver. Together, these data demonstrate a new, inexpensive approach to biomacromolecular delivery with the potential to target difficult-to-transfect organs, thus expanding the therapeutic potential of nucleic acids.</description>
      <author>Mikaela A. Gray, Michelle Seeler, Catalina Montoya, Jaeyoung Park, D. Linh, Kathryn A. Whitehead, Julie A. Champion</author>
      <pubDate>Mon, 28 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.1101/2025.04.25.650611</guid>
    </item>
    <item>
      <title>Event constrained programming</title>
      <link>https://doi.org/10.1016/j.compchemeng.2025.109145</link>
      <description>Daniel Ovalle, Stefan Mazzadi, Carl D. Laird, Ignacio E. Grossmann, Joshua L. Pulsipher, Computers &amp; Chemical Engineering. None(None)] 2025. https://openalex.org/W4409907298

                No abstract</description>
      <author>Daniel Ovalle, Stefan Mazzadi, Carl D. Laird, Ignacio E. Grossmann, Joshua L. Pulsipher</author>
      <pubDate>Tue, 01 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.1016/j.compchemeng.2025.109145</guid>
    </item>
    <item>
      <title>The evolving role of programming and LLMs in the development of self-driving laboratories</title>
      <link>https://doi.org/10.1063/5.0266757</link>
      <description>John R. Kitchin, APL Machine Learning. 3(2)] 2025. https://openalex.org/W4409962774

                Machine learning and automation are transforming scientific research, yet the implementation of self-driving laboratories (SDLs) remains costly and complex, and it remains difficult to learn how to use these facilities. To address this, we introduce Claude-Light, a lightweight, remotely accessible instrument designed for prototyping automation algorithms and machine learning workflows. Claude-Light integrates a REST API, a Raspberry Pi-based control system, and an RGB LED with a photometer that measures ten spectral outputs, providing a controlled but realistic experimental environment. This device enables users to explore automation at multiple levels, from basic programming and experimental design to machine learning-driven optimization. We demonstrate the application of Claude-Light in structured automation approaches, including traditional scripting, statistical design of experiments, and active learning methods. In addition, we explore the role of large language models (LLMs) in laboratory automation, highlighting their use in instrument selection, structured data extraction, function calling, and code generation. While LLMs present new opportunities for streamlining automation, they also introduce challenges related to reproducibility, security, and reliability. We discuss strategies to mitigate these risks while leveraging LLMs for enhanced efficiency in self-driving laboratories. Claude-Light provides a practical and accessible platform for students and researchers to develop automation skills and test algorithms before deploying them in larger-scale SDLs. By lowering the barrier to entry for automation in scientific research, this tool facilitates broader adoption of AI-driven experimentation and fosters innovation in autonomous laboratories.</description>
      <author>John R. Kitchin</author>
      <pubDate>Wed, 30 Apr 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://doi.org/10.1063/5.0266757</guid>
    </item>
  </channel>
</rss>
