#+title: Literature alerts with OpenAlex
#+author: John Kitchin
#+date: [2024-01-15 Mon]

This is a project to use https://openalex.org to create literature alerts. It creates an RSS feed and a results file with recently created entries. It also creates a GitHUB issue assigned to me, which notifies me when new entries are added.

You specify queries in this yaml file: [[./queries.yml]]

There is a Python package in [[./src/litalerts/]] that provides a CLI called ~litalerts~. That script is run a schedule set by [[./.github/workflows/scheduled.yml]].

The results are written to [[./results]] as org-files and it generates RSS feeds at [[./rss]].

How do you use this? I have not developed the best way to use this myself yet. Here are some ways I think you could do it. 

1. You could probably subscribe to the repo and get notified of updates.
2. In your browser go to https://github.com/jkitchin/literature-alerts/blob/main/results.org and see if you want to do anything with the results. They get replaced every time the script runs. Maybe one day I will explore keeping version, or writing to time-stamped files.
3. Subscribe to the rss feed and consume it as you see fit.
4. Clone the repo and open   [[./results.org]]  in Emacs. Interact with it as you see fit, e.g. refile entries, etc. It might be tricky to add notes, keep it running etc. There might be some git-fu, e.g. branching, etc. that makes it practical.

In Emacs you can set up elfeed like this with these RSS feeds:

#+BEGIN_SRC emacs-lisp :results silent
(require 'elfeed)
(setq elfeed-feeds '("https://raw.githubusercontent.com/jkitchin/literature-alerts/main/rss/water-splitting.xml"
		     "https://raw.githubusercontent.com/jkitchin/literature-alerts/main/rss/CO2RR.xml"
		     "https://raw.githubusercontent.com/jkitchin/literature-alerts/main/rss/authors.xml"))
#+END_SRC

Or go to some site like https://rssviewer.app/, paste in one of those urls, and click on view feed.

This is still a work in progress. Something not working? Feature requests? Post an issue at https://github.com/jkitchin/literature-alerts/issues.


* How does it work?

I use GitHUB Actions to run [[./script.py]] on a schedule. This script iterates through [[./queries.yml]] to construct URLs to query https://openalex.org. I use ~from_created_date~ in the filter which requires an OpenAlex premium API key. See https://openalex.org/pricing. OpenAlex gave me a premium API key for academic research. Thanks for that!

The API key is stored as a GitHUB secret so it is accessible to the Action script [[./.github/workflows/scheduled.yml]], but secure. This usually works, but apparently scheduled workflows are not always run on time (https://upptime.js.org/blog/2021/01/22/github-actions-schedule-not-working/). TBD if that is an issue. You can manually trigger the workflow at https://github.com/jkitchin/literature-alerts/actions/workflows/scheduled.yml.

The script generates some files, and I commit them to the repository so it is easy to access them. I might consider an alternative approach based on https://docs.github.com/en/actions/using-workflows/storing-workflow-data-as-artifacts


* Want to do it yourself?

You can use this repo as a template: https://github.com/new?template_name=literature-alerts&template_owner=jkitchin

You will want to modify these files:
- [[./queries.yml]] (for the queries you want)
- [[./.github/workflows/scheduled.yml]] (for the schedule you want)


If you want to do this yourself, you will need an OpenAlex premium API key. See https://openalex.org/pricing. Then, you will have to setup a repository secret for ~OPENALEX_API_KEY~ with the key they give you.

In your repo, go to something like  https://github.com/jkitchin/literature-alerts/settings/actions and give actions "Read and write permissions" under "Workflow permissions".


* Wishlist

- Figure out how to assign issues to specific users that are indicated in the queries.yml file. Maybe make an actions.sh file and then execute it later.
- Add delivery methods to yml, email, rss, org, etc.
- Consider pull-requests for other people to make their own queries? Would some constraints be needed? 

* Development notes

** DONE Run an action on a schedule
CLOSED: [2024-01-15 Mon 11:20]

See [[./.github/workflows/scheduled.yml]]. Adapted from https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule

This runs every 15 min. That might be the smallest interval supported by GitHUB.

#+BEGIN_EXAMPLE
on:
  schedule:
    - cron: '*/15 * * * *'
#+END_EXAMPLE


** DONE Have an action create an artifact
CLOSED: [2024-01-15 Mon 11:20]

probably a file, and maybe also a GH issue

Go to https://github.com/jkitchin/literature-alerts/settings/actions and give actions read/write permissions at the bottom.

You can commit results in an action. The downside of this is you have to pull before you can push again. That is probably ok

#+BEGIN_EXAMPLE
  build_artifact:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Create a file
        run: |
          date >> results.dat
          git config --global user.email "jkitchin@andrew.cmu.edu"
          git config --global user.name "John Kitchin"
          git add results.dat
          git commit results.dat -m "adding to results.dat"
          git push
#+END_EXAMPLE


** DONE Use a GH secret to save the API key
CLOSED: [2024-01-15 Mon 11:20]

The api key is secret, and you add it to an environment like this. Then in the script.py load it from the environment.

#+BEGIN_EXAMPLE
  openalex:
    runs-on: ubuntu-latest
    steps:
      - name: Install dependencies
        run: pip install requests
        
      - name: Use API key
        env:
          OPENALEX_API_KEY: ${{ secrets.OPENALEX_API_KEY }}
        run: |            
            python script.py
            git add results.dat
            git commit results.dat -m "adding new results to results.dat"
            git push
#+END_EXAMPLE



** DONE write a Python script using OpenAlex to get new articles
CLOSED: [2024-01-15 Mon 11:20]

See [[./script.py]]


** DONE Create a new issue when new things are found
CLOSED: [2024-01-15 Mon 11:20]

This would alert you that there is something to do.

https://github.com/marketplace/actions/create-an-issue


#+BEGIN_EXAMPLE
      - uses: JasonEtco/create-an-issue@v2        
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
#+END_EXAMPLE

there is not a lot of control, but it is ok.

It would be useful if it only did this when new entries are found. That would require some logic to see if the results.org file changed maybe, or some flag file.

It is possible it would be easier to do this in the script?

it is, I can do it with the gh cli.

** RSS feed

I can make an rss feed for this. See https://github.com/svpino/rfeed.

** DONE Separate the script logic
CLOSED: [2024-01-15 Mon 11:20]

There should be some simple yaml file maybe of queries to run, one line per query. The script could run and write results to some label?

something like this maybe? Each category could have more than one filter.

#+BEGIN_SRC jupyter-python
from yaml import load, Loader

doc = '''queries:
  - label: water splitting
    filter:
      # this concept is Oxygen Evolution
      - concepts.id:https%3A%2F%2Fopenalex.org%2FC135473242
      - title-and-abstract.search:oxygen%20evolution
  - label: authors
    filter:
      - author.id:https%3A%2F%2Fopenalex.org%2FA5003442464'''

d = load(doc, Loader=Loader)
for topic in d['queries']:
    for filter in topic['filter']:
        print(f'running {filter}, saving results to {topic["label"]}.xml')

#+END_SRC

#+RESULTS:
:RESULTS:
running concepts.id:https%3A%2F%2Fopenalex.org%2FC135473242, saving results to water splitting.xml
running title-and-abstract.search:oxygen%20evolution, saving results to water splitting.xml
running author.id:https%3A%2F%2Fopenalex.org%2FA5003442464, saving results to authors.xml
:END:

*** TODO Should these be written to separate feeds?

** TODO Advanced queries

It would be nice to make queries for these

- new citations of a paper
- new related paper

Maybe this is just getting the paper, checking the citations/related, and seeing if any are newer than the last time we checked.

*** Semantic similarities

Eventually I want to use sentence_transformers for similarity checks.

** DONE What are the best formats?
CLOSED: [2024-01-15 Mon 11:20]

- [X] RSS great for consumption in elfeed
- [X] org great for consumption in Emacs
- [ ] html/md great for consumption from GitHUB/browser

If I make the org format right, it will also render fine I think.

Should I publish it to gh-pages? Hard to say what the benefit would be, you can already read the results at https://github.com/jkitchin/literature-alerts/blob/main/results.org

** Rotating logs

It could be nice to have a rotating log

#+BEGIN_SRC jupyter-python
import logging
import time
from logging.handlers import TimedRotatingFileHandler
#----------------------------------------------------------------------
def create_timed_rotating_log(path):
    """"""
    logger = logging.getLogger("Rotating Log")
    logger.setLevel(logging.INFO)
    
    handler = TimedRotatingFileHandler(path,
                                       when="m",
                                       interval=1,
                                       backupCount=5)
    logger.addHandler(handler)
    
    for i in range(6):
        logger.info("This is a test!")
        time.sleep(75)
#----------------------------------------------------------------------

log_file = "timed_test.log"
create_timed_rotating_log(log_file)
#+END_SRC

#+RESULTS:


#+BEGIN_EXAMPLE    
            if [ -f MAKEISSUE ]; then
                gh issue create --label "new references" --assignee jkitchin --title "New references found: `date`" --body "New references to look at. See [results](../blob/main/results)."
            fi
#+END_EXAMPLE
