* Development notes

** DONE Run an action on a schedule
CLOSED: [2024-01-15 Mon 11:20]

See [[./.github/workflows/scheduled.yml]]. Adapted from https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule

This runs every 15 min. That might be the smallest interval supported by GitHUB.

#+BEGIN_EXAMPLE
on:
  schedule:
    - cron: '*/15 * * * *'
#+END_EXAMPLE


** DONE Have an action create an artifact
CLOSED: [2024-01-15 Mon 11:20]

probably a file, and maybe also a GH issue

Go to https://github.com/jkitchin/literature-alerts/settings/actions and give actions read/write permissions at the bottom.

You can commit results in an action. The downside of this is you have to pull before you can push again. That is probably ok

#+BEGIN_EXAMPLE
  build_artifact:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Create a file
        run: |
          date >> results.dat
          git config --global user.email "jkitchin@andrew.cmu.edu"
          git config --global user.name "John Kitchin"
          git add results.dat
          git commit results.dat -m "adding to results.dat"
          git push
#+END_EXAMPLE


** DONE Use a GH secret to save the API key
CLOSED: [2024-01-15 Mon 11:20]

The api key is secret, and you add it to an environment like this. Then in the script.py load it from the environment.

#+BEGIN_EXAMPLE
  openalex:
    runs-on: ubuntu-latest
    steps:
      - name: Install dependencies
        run: pip install requests
        
      - name: Use API key
        env:
          OPENALEX_API_KEY: ${{ secrets.OPENALEX_API_KEY }}
        run: |            
            python script.py
            git add results.dat
            git commit results.dat -m "adding new results to results.dat"
            git push
#+END_EXAMPLE



** DONE write a Python script using OpenAlex to get new articles
CLOSED: [2024-01-15 Mon 11:20]

See [[./script.py]]


** DONE Create a new issue when new things are found
CLOSED: [2024-01-15 Mon 11:20]

This would alert you that there is something to do.

https://github.com/marketplace/actions/create-an-issue


#+BEGIN_EXAMPLE
      - uses: JasonEtco/create-an-issue@v2        
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
#+END_EXAMPLE

there is not a lot of control, but it is ok.

It would be useful if it only did this when new entries are found. That would require some logic to see if the results.org file changed maybe, or some flag file.

It is possible it would be easier to do this in the script?

it is, I can do it with the gh cli.

** RSS feed

I can make an rss feed for this. See https://github.com/svpino/rfeed.

** DONE Separate the script logic
CLOSED: [2024-01-15 Mon 11:20]

There should be some simple yaml file maybe of queries to run, one line per query. The script could run and write results to some label?

something like this maybe? Each category could have more than one filter.

#+BEGIN_SRC jupyter-python
from yaml import load, Loader

doc = '''queries:
  - label: water splitting
    filter:
      # this concept is Oxygen Evolution
      - concepts.id:https%3A%2F%2Fopenalex.org%2FC135473242
      - title-and-abstract.search:oxygen%20evolution
  - label: authors
    filter:
      - author.id:https%3A%2F%2Fopenalex.org%2FA5003442464'''

d = load(doc, Loader=Loader)
for topic in d['queries']:
    for filter in topic['filter']:
        print(f'running {filter}, saving results to {topic["label"]}.xml')

#+END_SRC

#+RESULTS:
:RESULTS:
running concepts.id:https%3A%2F%2Fopenalex.org%2FC135473242, saving results to water splitting.xml
running title-and-abstract.search:oxygen%20evolution, saving results to water splitting.xml
running author.id:https%3A%2F%2Fopenalex.org%2FA5003442464, saving results to authors.xml
:END:

